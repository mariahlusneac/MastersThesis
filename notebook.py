# -*- coding: utf-8 -*-
"""mai_oficial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NSd-cs0g4tAuHQZIhTcR6zgpnfAiApn2
"""

import os
import numpy as np
from matplotlib import pyplot as plt
import matplotlib.pylab as pylab
import skimage.io as io
from skimage.color import rgb2gray
from PIL import Image, ImageEnhance

from sklearn.model_selection import train_test_split

from keras.models import Model, Input
from keras.models import load_model
from keras.layers import Input as Inp
from keras.layers import Conv2D, Conv2DTranspose, Activation, Concatenate, \
  Dropout, BatchNormalization, LeakyReLU, Lambda, MaxPooling2D, Dense, \
  UpSampling2D, Add
from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator

import tensorflow as tf
import tensorflow.keras.backend as K
from tensorflow.keras.optimizers import Adam
import random

import cv2 as cv
from pathlib import Path

from copy import deepcopy

from tensorflow.keras import layers
!pip install -U tensorflow-addons

import tensorflow_addons as tfa
import keras

import pickle

# %tensorboard --logdir '/content/drive/My Drive/Disertatie/Models/kiunet/self_attention/nr_epochs=30/2/tensorboard_logs'

# %load_ext tensorboard

def get_specific_path(path_general, *path_chunks):
  return os.path.join(path_general, *path_chunks)

# data reading
def read_data(path_data, x_dir_name, y_dir_name, img_ext = '*.jpg'):
  x_dir = get_specific_path(path_data, x_dir_name, img_ext)
  y_dir = get_specific_path(path_data, y_dir_name, img_ext)

  x = io.ImageCollection(x_dir)
  y = io.ImageCollection(y_dir)

  x = list(x)
  y = list(y)

  return x, y

# data preprocessing
def get_min_dimensions(x):
  shapes0 = np.array([z.shape[0] for z in x])
  shapes1 = np.array([z.shape[1] for z in x])
  shape_min0_idx = np.argmin(shapes0)
  shape_min1_idx = np.argmin(shapes1)
  min_dim0 = x[shape_min0_idx].shape[0]
  min_dim1 = x[shape_min1_idx].shape[1]
  return min_dim0, min_dim1

def resize_images_to_dims(images_list, dim1, dim2):
  for i in range(len(images_list)):
    img = Image.fromarray(images_list[i])
    img = img.resize((dim1, dim2))
    images_list[i] = np.array(img)
  return images_list

def scale_images(images_list):
  for i in range(len(images_list)):
    images_list[i] = images_list[i]/255
  return images_list

def reduce_type(images_list):
  images_list = np.asarray(images_list, dtype=np.float32)
  return images_list

def preprocess_data(x, y, dim1_wanted=-1, dim2_wanted=-1, dataset='NA'):
  if dim1_wanted != -1 and dim2_wanted != -1:
    min_dim1, min_dim2 = get_min_dimensions(x)
    if dim1_wanted <= min_dim1 and dim2_wanted <= min_dim2:
      x = resize_images_to_dims(x, dim1_wanted, dim2_wanted)
      y = resize_images_to_dims(y, dim1_wanted, dim2_wanted)
    else:
      min_dim = min(min_dim1, min_dim2)
      if min_dim % 2 == 1:
        min_dim -= 1
      x = resize_images_to_dims(x, min_dim, min_dim)
      y = resize_images_to_dims(y, min_dim, min_dim)
  
  x = scale_images(x)
  y = scale_images(y)

  x = np.array(x)
  y = np.array(y)

  if len(y.shape) != 3:
    y = rgb2gray(y)

  x = reduce_type(x)
  y = reduce_type(y)

  # if dataset == 'glas':
  #   y = np.where(y != 0, 1, y)

  return x, y

def split(x, y, test_fraction=0.1, val_fraction=0.1):
  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_fraction, random_state=1)
  val_fraction_relative_to_train = val_fraction * x.shape[0] / x_train.shape[0]
  x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_fraction_relative_to_train, random_state=1)
  return x_train, y_train, x_test, y_test, x_val, y_val

# # for rite original
# def split(x, y, test_fraction=0.3, val_fraction=0.2):
#   x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_fraction, random_state=1)
#   val_fraction_relative_to_train = val_fraction * x.shape[0] / x_train.shape[0]
#   x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_fraction_relative_to_train, random_state=1)
#   return x_train, y_train, x_test, y_test, x_val, y_val

# plot results, plot history, show test results
def plot_results(x_test, y_test, y_pred, img_index=0, fig_size=10):
  f, axarr = plt.subplots(2,2)
  f.set_figheight(fig_size)
  f.set_figwidth(fig_size)

  axarr[0,0].imshow(x_test[img_index])
  axarr[0,1].imshow(y_test[img_index], cmap='gray')
  axarr[1,0].imshow(y_pred[img_index][:, :, 0], cmap='gray')
  y_pred_thresholded = np.round(y_pred[img_index])
  axarr[1,1].imshow(y_pred_thresholded[:, :, 0], cmap='gray')

  axarr[0,0].title.set_text('Original')
  axarr[0,1].title.set_text('Ground truth')
  axarr[1,0].title.set_text('Predicted')
  axarr[1,1].title.set_text('Predicted thresholded')

def plot_history(metric, history):  # choice of ['mae', 'mse', 'meanIoU', 'accuracy', 'precision', 'recall' 'dice']
  plt.plot(history[f'custom_{metric}_metric'])
  plt.plot(history[f'val_custom_{metric}_metric'])
  plt.title(f'Model {metric}')
  plt.ylabel(metric)
  plt.xlabel('epoch')
  plt.legend(['train', 'val'], loc='upper left')
  plt.show()

def get_results_test(results):
  print('Loss     ', results['loss'])
  print('MAE      ', results['mae'])
  print('MSE      ', results['mse'])
  print('MeanIoU  ', results['meaniou'])
  print('Accuracy ', results['accuracy'])
  print('Precision', results['precision'])
  print('Recall   ', results['recall'])
  print('Dice     ', results['dice'])

# CRFB blocks
def crfb_unet(out_unet, out_kinet, scale_factor_kinet, n_filters, kernel_size, **kwargs):
  first_member = out_unet

  # constructing second_member by applying layers on ki-net
  conv = Conv2D(n_filters, kernel_size, strides=1, padding='same')(out_kinet)
  bn = BatchNormalization()(conv)
  activ = Activation('relu')(bn)
  if scale_factor_kinet[0] >= 1:
    interp = UpSampling2D(scale_factor_kinet)(activ)
  else:
    interp = MaxPooling2D((1/scale_factor_kinet[0], 1/scale_factor_kinet[1]))(activ)
  second_member = interp
  
  added = Add()([first_member, second_member])

  if 'self_attention' in kwargs.keys():
    if kwargs['self_attention']:
      num_patches = int(added.shape[1] * added.shape[2] / (kwargs['patch_size'])**2)
      self_att = self_attention_layer(added, num_patches, n_filters, kwargs['num_transformer_blocks'])
      return self_att
  return added


def crfb_kinet(out_kinet, out_unet, scale_factor_unet, n_filters, kernel_size, **kwargs):
  first_member = out_kinet

  # constructing second_member by applying layers on u-net
  conv = Conv2D(n_filters, kernel_size, strides=1, padding='same')(out_unet)
  bn = BatchNormalization()(conv)
  activ = Activation('relu')(bn)
  if scale_factor_unet[0] >= 1:
    interp = UpSampling2D(scale_factor_unet)(activ)
  else:
    interp = MaxPooling2D((1/scale_factor_unet[0], 1/scale_factor_unet[1]))(activ)
  second_member = interp

  added = Add()([first_member, second_member])

  if 'self_attention' in kwargs.keys():
    if kwargs['self_attention']:
      num_patches = int(added.shape[1] * added.shape[2] / (kwargs['patch_size'])**2)
      # self_att = self_attention_layer(added, num_patches, kwargs['embedding_dim'], kwargs['num_transformer_blocks'])
      self_att = self_attention_layer(added, num_patches, n_filters, kwargs['num_transformer_blocks'])

      return self_att
  return added

# Encoder blocks
def enc_unet(inp, n_filters, kernel_size):
  conv = Conv2D(n_filters, kernel_size, strides=1, padding='same')(inp)
  maxpool = MaxPooling2D((2, 2))(conv)
  bn = BatchNormalization()(maxpool)
  activ = Activation('relu')(bn)
  return activ


def enc_kinet(inp, n_filters, kernel_size):
  conv = Conv2D(n_filters, kernel_size, strides=1, padding='same')(inp)
  interp = UpSampling2D((2, 2))(conv)
  bn = BatchNormalization()(interp)
  activ = Activation('relu')(bn)
  return activ

# Decoder blocks
def dec_unet(inp, n_filters, kernel_size, dropout=False):
  conv = Conv2D(n_filters, kernel_size, strides=1, padding='same')(inp)
  interp = UpSampling2D((2, 2))(conv)
  bn = BatchNormalization()(interp)
  if dropout:
    dropped = Dropout(0.15)(bn, training=True)
  else:
    dropped = bn
  activ = Activation('relu')(dropped)
  return activ


def dec_kinet(inp, n_filters, kernel_size, dropout=False):
  conv = Conv2D(n_filters, kernel_size, strides=1, padding='same')(inp)
  maxpool = MaxPooling2D((2, 2))(conv)
  bn = BatchNormalization()(maxpool)
  if dropout:
    dropped = Dropout(0.15)(bn, training=True)
  else:
    dropped = bn
  activ = Activation('relu')(dropped)
  return activ

def general_attention(enc, dec, enc_filters):
  enc = Conv2DTranspose(1, (1, 1), strides=1, padding='same')(enc)
  dec = Conv2DTranspose(1, (1, 1), strides=1, padding='same')(dec)

  added = tf.keras.layers.Add()([enc, dec])
  activ = Activation('relu')(added)
  conved = Conv2DTranspose(enc_filters, (1, 1), strides=1, padding='same')(activ)
  activ = Activation('sigmoid')(conved)

  enc_multiplied = tf.keras.layers.Multiply()([enc, activ])
  return enc_multiplied

class ReconstructionLayer(layers.Layer):
    # (None, 4096, 64) =>(dense) (None, 4096, 12) =>(reshape) (None, 4096, 4, 3) =>(reshape) (None, 4096, 2, 2, 3) => (reshape) (None, 64, 64, 2, 2, 3) =>(transpose) (None, 64, 2, 64, 2, 3) =>(reshape) (None, 128, 64, 2, 3) =>(concat) (None, 128, 128, 3)
    def __init__(self, image_size, patch_size, nr_channels, batch_size, **kwargs):
        super(ReconstructionLayer, self).__init__(**kwargs)
        if batch_size == None:
          self.batch_size = batch_size
        else:
          self.batch_size = int(batch_size)
        self.image_size = int(image_size)
        self.patch_size = int(patch_size)
        self.nr_channels = int(nr_channels)
        self.nr_patches_row = int(self.image_size / self.patch_size)
        self.nr_patches = int((self.nr_patches_row) ** 2)

    def get_config(self):
            config = super().get_config()
            config.update({
                "image_size": self.image_size,
                "patch_size": self.patch_size,
                "nr_channels": self.nr_channels,
                "batch_size": self.batch_size,
            })
            return config


    def call(self, x):
        x1 = layers.Dense(x.shape[-1] * self.patch_size * self.patch_size)(x) # (None, 4096, 12)
        x1 = tf.reshape(x1, (self.batch_size, self.nr_patches, self.patch_size*self.patch_size, self.nr_channels)) #  (None, 4096, 4, 3)
        x1 = tf.reshape(x1, (self.batch_size, self.nr_patches_row, self.nr_patches_row, self.patch_size, self.patch_size, self.nr_channels)) #  (None, 64, 64, 2, 2, 3)
        x1 = tf.transpose(x1, [0, 1, 3, 2, 4, 5]) # (None, 64, 2, 64, 2, 3)
        x1 = tf.reshape(x1, (self.batch_size, self.image_size, self.image_size, self.nr_channels)) # (None, 128, 128, 3)
        return x1

def transformer_encoder(x, embedding_dim, num_heads, dim_coefficient, attention_dropout, projection_dropout):
    residual_1 = x
    x = layers.LayerNormalization(epsilon=1e-5)(x)
    x = layers.MultiHeadAttention(
        num_heads=num_heads, key_dim=embedding_dim, dropout=attention_dropout)(x, x)
    x = layers.add([x, residual_1])
    residual_2 = x
    x = layers.LayerNormalization(epsilon=1e-5)(x)
    return x

class PatchExtract(layers.Layer):
    def __init__(self, patch_size, **kwargs):
        super(PatchExtract, self).__init__(**kwargs)
        self.patch_size = patch_size

    def get_config(self):
            config = super().get_config()
            config.update({
                "patch_size": self.patch_size,
            })
            return config

    def call(self, images):
        batch_size = tf.shape(images)[0]
        patches = tf.image.extract_patches(
            images=images,
            sizes=(1, self.patch_size, self.patch_size, 1),
            strides=(1, self.patch_size, self.patch_size, 1),
            rates=(1, 1, 1, 1),
            padding="VALID",
        )
        patch_dim = patches.shape[-1]
        patch_num = patches.shape[1]
        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))  # shape (None, 4096, 12)


class PatchEmbedding(layers.Layer):
    def __init__(self, num_patch, embed_dim, **kwargs):
        super(PatchEmbedding, self).__init__(**kwargs)
        self.num_patch = num_patch # 4096
        self.embed_dim = embed_dim
        self.proj = layers.Dense(embed_dim) # 64
        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)

    def get_config(self):
            config = super().get_config()
            config.update({
                "num_patch": self.num_patch,
                "embed_dim": self.embed_dim,
            })
            return config

    def call(self, patch):
        pos = tf.range(start=0, limit=self.num_patch, delta=1)
        return self.proj(patch) + self.pos_embed(pos) # (None, 4096, 64) + (None, 4096, 64)

def self_attention_layer(x, num_patches, embedding_dim, num_transformer_blocks, num_heads=4, dim_coefficient=4, attention_dropout=0.2, projection_dropout=0.2, batch_size=2):
    initial_shape_1 = x.shape[1]
    initial_shape_2 = x.shape[2]
    x = PatchExtract(patch_size)(x)
    x = PatchEmbedding(num_patches, embedding_dim)(x)
    for _ in range(num_transformer_blocks):
        x = transformer_encoder(
            x,
            embedding_dim,
            num_heads,
            dim_coefficient,
            attention_dropout,
            projection_dropout)
    x = ReconstructionLayer(initial_shape_1, patch_size, x.shape[-1], batch_size)(x)
    return x

custom_objects = {
    'custom_mae_metric': custom_mae_metric, 
    'custom_mse_metric': custom_mse_metric, 
    'custom_meanIoU_metric': custom_meanIoU_metric,
    'custom_accuracy_metric': custom_accuracy_metric,
    'custom_precision_metric': custom_precision_metric, 
    'custom_recall_metric': custom_recall_metric, 
    'custom_dice_metric': custom_dice_metric,
    'PatchExtract': PatchExtract,
    'PatchEmbedding': PatchEmbedding,
    'ReconstructionLayer': ReconstructionLayer}

# U-Net
def unet(x_train_shape, final_layer_activation, attention, **kwargs):
  inp = Input(x_train_shape)

  # 1 enc
  out = enc_unet(inp, 16, 3)
  u1 = out

  # 2 enc
  out = enc_unet(out, 32, 3)
  u2 = out   # 32

  # 3 enc
  out = enc_unet(out, 64, 3)
  ### End of encoder block


  ### Start Decoder
  # 3 dec
  out = dec_unet(out, 32, 3)
  # ATTENTION
  if attention:
    enc = u2
    dec = out
    enc_multiplied = general_attention(enc, dec, 32)
    out = dec
    u2 = enc_multiplied
  if 'self_attention' in kwargs.keys():
    if kwargs['self_attention']:
      num_patches = int(out.shape[1] * out.shape[2] / (kwargs['patch_size'])**2)
      out = self_attention_layer(out, num_patches, 32, kwargs['num_transformer_blocks'])
  out = Add()([out, u2])

  # 2 dec
  out = dec_unet(out, 16, 3)  # 64
  # ATTENTION
  if attention:
    enc = u1   # 32
    dec = out  # 32
    enc_multiplied = general_attention(enc, dec, 16)
    out = dec
    u1 = enc_multiplied
  if 'self_attention' in kwargs.keys():
    if kwargs['self_attention']:
      num_patches = int(out.shape[1] * out.shape[2] / (kwargs['patch_size'])**2)
      out = self_attention_layer(out, num_patches, 16, kwargs['num_transformer_blocks'])
  out = Add()([out, u1])


  # 1 dec
  out = dec_unet(out, 8, 3)

  out = Activation('relu')(out)

  # se da adunarea la un conv final
  out = Conv2D(1, 3, strides=1, padding='same')(out)

  out = Activation(final_layer_activation)(out)

  # print(out.shape)

  model = Model(inp, out)

  return model

# KiU-Net
def kiunet(x_train_shape, final_layer_activation, attention, **kwargs):

  inp = Input(x_train_shape)

  # 1 enc
  out = enc_unet(inp, 16, 3)
  print('enc1', out.shape)    # 64

  out1 = enc_kinet(inp, 16, 3)
  tmp = out
  # 1 crfb
  out = crfb_unet(out, out1, (0.25, 0.25), 16, 3)
  out1 = crfb_kinet(out1, tmp, (4, 4), 16, 3)

  u1 = out
  o1 = out1

  # 2 enc
  out = enc_unet(out, 32, 3)
  print('enc2', out.shape)    # 64
  out1 = enc_kinet(out1, 32, 3)
  tmp = out
  # 2 crfb
  out = crfb_unet(out, out1, (0.0625, 0.0625), 32, 3)
  out1 = crfb_kinet(out1, tmp, (16, 16), 32, 3)

  u2 = out
  o2 = out1

  # 3 enc
  out = enc_unet(out, 64, 3)
  print('enc3', out.shape)    # 64
  out1 = enc_kinet(out1, 64, 3)
  tmp = out
  # 3 crfb
  out = crfb_unet(out, out1, (0.015625, 0.015625), 64, 3, **kwargs)
  # out1 = crfb_kinet(out1, tmp, (64, 64), 64, 3, **kwargs)
  out1 = crfb_kinet(out1, tmp, (64, 64), 64, 3)
  # print('\nEND ENCODER\n')
  ### End of encoder block


  ### Start Decoder
  # 3 dec
  out = dec_unet(out, 32, 3)
  out1 = dec_kinet(out1, 32, 3)

  tmp = out
  # 2 crfb'
  out = crfb_unet(out, out1, (0.0625, 0.0625), 32, 3, **kwargs)
  # out1 = crfb_kinet(out1, tmp, (16, 16), 32, 3, **kwargs)
  out1 = crfb_kinet(out1, tmp, (16, 16), 32, 3)

  # se sumeaza 2 crfb' cu 2 crfb (pt unet si pt kinet)
  # print('se sumeaza out + u2', out.shape, u2.shape)
  # ATTENTION unet!
  if attention:
    enc = u2
    dec = out
    enc_multiplied = general_attention(enc, dec, 32)
    out = dec
    u2 = enc_multiplied
  # ATTENTION !
  out = Add()([out, u2])

  # print('se sumeaza out1 + o2', out1.shape, o2.shape)
  # ATTENTION kinet!
  if attention:
    enc = o2
    dec = out1
    enc_multiplied = general_attention(enc, dec, 32)
    out1 = dec
    o2 = enc_multiplied
  # ATTENTION !
  # print('BEFORE ADDDD', out1.shape, o2.shape)
  out1 = Add()([out1, o2])

  # 2 dec
  out = dec_unet(out, 16, 3)
  out1 = dec_kinet(out1, 16, 3)
  tmp = out
  # 1 crfb'
  out = crfb_unet(out, out1, (0.25, 0.25), 16, 3, **kwargs)
  # out1 = crfb_kinet(out1, tmp, (4, 4), 16, 3, **kwargs)
  out1 = crfb_kinet(out1, tmp, (4, 4), 16, 3)

  
  # se sumeaza 1 crfb' cu 1 crfb
  # print('se sumeaza', out.shape, u1.shape)
  # ATTENTION unet!
  if attention:
    enc = u1
    dec = out
    enc_multiplied = general_attention(enc, dec, 16)
    out = dec
    u1 = enc_multiplied
  # ATTENTION !
  out = Add()([out, u1])
  # print('se sumeaza', out1.shape, o1.shape)
  # ATTENTION kinet!
  if attention:
    enc = o1
    dec = out1
    enc_multiplied = general_attention(enc, dec, 16)
    out1 = dec
    o1 = enc_multiplied
  # ATTENTION !
  out1 = Add()([out1, o1])

  # 1 dec
  out = dec_unet(out, 8, 3)
  out1 = dec_kinet(out1, 8, 3)

  # se sumeaza 1 dec unet cu 1 dec kinet
  out = Add()([out, out1])
  out = Activation('relu')(out)

  # se da adunarea la un conv final
  out = Conv2D(1, 3, strides=1, padding='same')(out)

  out = Activation(final_layer_activation)(out)

  # print(out.shape)

  model = Model(inp, out)

  return model

# get model
def get_model(model_name, input_shape, final_layer_activation, attention, **kwargs):
  if model_name == 'kiunet':
    model = kiunet
  elif model_name == 'unet':
    model = unet
  # elif model_name == 'hardnet_mseg':
  #   return hardnet_mseg
  return model(input_shape, final_layer_activation, attention, **kwargs)

# get model path
def get_model_path(path_models, dataset, model_name, attention, **other_model_characteristics):
  if model_name == 'unet':
    model_dir = 'unet'
  elif model_name == 'kiunet':
    model_dir = 'kiunet'
  elif model_name == 'hardnet-mseg':
    model_dir = 'hardnet-mseg'

  if attention is True:
    attention_dir = 'with_attention'
  elif attention is False:
    attention_dir = 'no_attention'
  elif attention == 'self_attention':
    attention_dir = 'self_attention'

  path_chunks = []

  for key in other_model_characteristics:
    path_chunks.append(f"{key}={other_model_characteristics[key]}")

  # pt rite original
  # model_path = os.path.join(os.path.join(path_models, dataset, 'original'), model_dir, attention_dir, *path_chunks)
  # pt rite kiunet
  if (attention is True or attention is False) and model_name == 'kiunet' and dataset == 'rite':
    model_path = os.path.join(os.path.join(path_models, dataset), model_dir, 'with_metrics_updated', attention_dir, *path_chunks)
  else:
    model_path = os.path.join(path_models, dataset, model_dir, attention_dir, *path_chunks)
  
  if not os.path.exists(model_path):
    os.makedirs(model_path)

  return model_path

# custom metrics
def custom_mae_metric(y_true, y_pred):
    difference = tf.math.abs(y_true - y_pred)
    return tf.reduce_mean(difference, axis=-1)


def custom_mse_metric(y_true, y_pred):
    # y_pred = tf.math.round(y_pred)
    squared_difference = tf.square(y_true - y_pred)
    return tf.reduce_mean(squared_difference, axis=-1)


def custom_precision_metric_train(y_true, y_pred):
    y_pred = tf.math.round(y_pred).numpy()
    y_true = tf.math.round(y_true).numpy()
    tp = np.sum(np.logical_and(y_pred == 1, y_true == 1))
    fp = np.sum(np.logical_and(y_pred == 1, y_true == 0))
    return tp / (tp + fp + K.epsilon())
def custom_precision_metric_evaluate(y_true, y_pred):
    y_pred = tf.math.round(y_pred)
    y_true = tf.math.round(y_true)
    tp = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 1, y_true == 1), tf.float32))
    fp = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 1, y_true == 0), tf.float32))
    return tp / (tp + fp + K.epsilon())
def custom_precision_metric(y_true, y_pred, evaluate=False):
  if evaluate:
    return custom_precision_metric_evaluate(y_true, y_pred)
  else:
    return custom_precision_metric_train(y_true, y_pred)


def custom_recall_metric_train(y_true, y_pred):
    y_pred = tf.math.round(y_pred).numpy()
    y_true = tf.math.round(y_true).numpy()
    tp = np.sum(np.logical_and(y_pred == 1, y_true == 1))
    fn = np.sum(np.logical_and(y_pred == 0, y_true == 1))
    return tp / (tp + fn + K.epsilon())
def custom_recall_metric_evaluate(y_true, y_pred):
    y_pred = tf.math.round(y_pred)
    y_true = tf.math.round(y_true)
    tp = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 1, y_true == 1), tf.float32))
    fn = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 0, y_true == 1), tf.float32))
    return tp / (tp + fn + K.epsilon())
def custom_recall_metric(y_true, y_pred, evaluate=False):
  if evaluate:
    return custom_recall_metric_evaluate(y_true, y_pred)
  else:
    return custom_recall_metric_train(y_true, y_pred)


def custom_meanIoU_metric_train(y_true, y_pred):
    y_pred = tf.math.round(y_pred)
    y_true = tf.math.round(y_true)
    # equal = tf.math.equal(y_pred, y_true)
    # reshaped = tf.reshape(equal, shape=(-1,))
    # print('\nreshaped', reshaped.shape, reshaped)
    # unique, _, counts = tf.unique_with_counts(reshaped)
    # print('counts', counts.shape, counts)
    # unique = unique.numpy()
    # idx_count_equal = np.where(unique == True)[0][0]
    # print('unique', unique.shape, unique)
    # print('1', np.where(unique == False))

    # if np.where(unique == False).shape[0] == 0:

    # print('2', np.where(unique == False)[0])
    # idx_count_diff = np.where(unique == False)[0][0]
    # intersection_cardinal = counts[idx_count_equal].numpy()
    # diff_cardinal = counts[idx_count_diff].numpy()
    # union_cardinal = 2 * diff_cardinal + intersection_cardinal
    # return intersection_cardinal / union_cardinal
    precision = custom_precision_metric(y_true, y_pred)
    recall = custom_recall_metric(y_true, y_pred)
    product = precision * recall
    return product / (precision + recall - product + K.epsilon())


def custom_meanIoU_metric_evaluate(y_true, y_pred):
    y_pred = tf.math.round(y_pred)
    equal = tf.math.equal(y_pred, y_true)
    reshaped = tf.reshape(equal, shape=(-1,))
    unique, _, counts = tf.unique_with_counts(reshaped)
    idx_count_equal = tf.where(unique == True)[0][0]
    idx_count_diff = tf.where(unique == False)[0][0]
    intersection_cardinal = counts[idx_count_equal]
    diff_cardinal = counts[idx_count_diff]
    union_cardinal = 2 * diff_cardinal + intersection_cardinal
    return intersection_cardinal / (union_cardinal + K.epsilon())
    # return intersection_cardinal / (union_cardinal)
def custom_meanIoU_metric(y_true, y_pred, evaluate=False):
  if evaluate:
    return custom_meanIoU_metric_evaluate(y_true, y_pred)
  else:
    return custom_meanIoU_metric_train(y_true, y_pred)


def custom_accuracy_metric_train(y_true, y_pred):
    y_pred = tf.math.round(y_pred).numpy()
    y_true = tf.math.round(y_true).numpy()
    tp = np.sum(np.logical_and(y_pred == 1, y_true == 1))
    tn = np.sum(np.logical_and(y_pred == 0, y_true == 0))
    fp = np.sum(np.logical_and(y_pred == 1, y_true == 0))
    fn = np.sum(np.logical_and(y_pred == 0, y_true == 1))
    return (tp + tn) / (tp + tn + fp + fn + K.epsilon())
def custom_accuracy_metric_evaluate(y_true, y_pred):
    y_pred = tf.math.round(y_pred)
    y_true = tf.math.round(y_true)
    tp = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 1, y_true == 1), tf.float32))
    tn = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 0, y_true == 0), tf.float32))
    fp = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 1, y_true == 0), tf.float32))
    fn = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 0, y_true == 1), tf.float32))
    return (tp + tn) / (tp + tn + fp + fn + K.epsilon())
def custom_accuracy_metric(y_true, y_pred, evaluate=False):
  if evaluate:
    return custom_accuracy_metric_evaluate(y_true, y_pred)
  else:
    return custom_accuracy_metric_train(y_true, y_pred)

def custom_dice_metric_train(y_true, y_pred):
    y_pred = tf.math.round(y_pred)
    y_true = tf.math.round(y_true)
    tp = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 1, y_true == 1), tf.float32))
    fp = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 1, y_true == 0), tf.float32))
    fn = tf.math.reduce_sum(tf.cast(tf.math.logical_and(y_pred == 0, y_true == 1), tf.float32))
    return 2 * tp / (2 * tp + fp + fn + K.epsilon())
def custom_dice_metric_evaluate(y_true, y_pred):
    y_pred = tf.math.round(y_pred).numpy()
    y_true = tf.math.round(y_true).numpy()
    tp = np.sum(np.logical_and(y_pred == 1, y_true == 1))
    fp = np.sum(np.logical_and(y_pred == 1, y_true == 0))
    fn = np.sum(np.logical_and(y_pred == 0, y_true == 1))
    return 2 * tp / (2 * tp + fp + fn + K.epsilon())
def custom_dice_metric(y_true, y_pred, evaluate=True):
  if evaluate:
    return custom_dice_metric_evaluate(y_true, y_pred)
  else:
    return custom_dice_metric_train(y_true, y_pred)

# callbacks
def get_callback_model_checkpoint(current_model_path, save_weights_only=False, monitor='val_loss', mode='auto', save_best_only=True):
  return ModelCheckpoint(
      filepath=os.path.join(current_model_path, 'model_epoch{epoch:2d}_valloss{' + monitor + ':.2f}.hdf5'),
      save_weights_only=save_weights_only,
      monitor=monitor,
      mode=mode,
      save_best_only=save_best_only)

def get_callback_reduce_lr(monitor='val_loss', factor=0.1, patience=10):
  return ReduceLROnPlateau(
      monitor='val_loss', 
      factor=0.1,
      patience=10)

def get_callback_tensorboard(tensorboard_dir):
  return tf.keras.callbacks.TensorBoard(tensorboard_dir)

def load_best_model(model_path, *custom_objects):
  paths = sorted(Path(model_path).iterdir(), key=os.path.getmtime)
  model = load_model(list(filter(lambda x: 'hdf5' in x.as_posix(), paths))[-1].as_posix(), custom_objects=custom_objects[0])
  return model

def save_train_artifacts(model, current_model_path, batch_size, history, x_test, y_test):
  # save history for training
  np.save(os.path.join(current_model_path, 'history.npy'), history.history)

  # save test prediction
  y_pred = model.predict(x_test, batch_size=batch_size)
  np.save(os.path.join(current_model_path, 'y_pred.npy'), y_pred)

  # save test loss and metrics 
  # x_test2 = np.asarray(x_test, dtype=np.float32)
  # y_test2 = np.asarray(y_test, dtype=np.float32)
  results = model.evaluate(x_test, y_test, batch_size=batch_size)
  res = {'loss': results[0],
        'mae': results[1],
        'mse': results[2],
        'meaniou': results[3],
        'accuracy': results[4],
        'precision': results[5],
        'recall': results[6],
        'dice': results[7]}
  with open(get_specific_path(current_model_path, 'test_results.pickle'), 'wb') as handle:
      pickle.dump(res, handle, protocol=pickle.HIGHEST_PROTOCOL)


def load_train_artifacts(current_model_path, **kwargs):
  history = np.load(os.path.join(current_model_path, 'history.npy'), allow_pickle=True).item()
  y_pred = np.load(os.path.join(current_model_path, 'y_pred.npy'), allow_pickle=True)
  try:
    with open(get_specific_path(current_model_path, 'test_results.pickle'), 'rb') as handle:
        results = pickle.load(handle)
  except:
    x_test = kwargs['x_test']
    y_test = kwargs['y_test']
    batch_size = kwargs['batch_size']
    results = kwargs['model'].evaluate(x_test, y_test, batch_size=batch_size)
    results = {'loss': results[0],
        'mae': results[1],
        'mse': results[2],
        'meaniou': results[3],
        'accuracy': results[4],
        'precision': results[5],
        'recall': results[6],
        'dice': results[7]}
  
  return history, y_pred, results

def plot_results_all(original, y_pred_unet_noatt, y_pred_unet_ag, y_pred_unet_sa, y_pred_kiunet_noatt, y_pred_kiunet_ag, y_pred_kiunet_sa, gt):
  params = {'axes.titlesize':'x-large'}
  pylab.rcParams.update(params)
  height = 10
  width = 25
  f, axarr = plt.subplots(2,5)
  f.set_figheight(height)
  f.set_figwidth(width)

  axarr[0,0].imshow(original)
  axarr[0,1].imshow(y_pred_unet_noatt[:, :, 0], cmap='gray')
  axarr[0,2].imshow(y_pred_unet_ag[:, :, 0], cmap='gray')
  axarr[0,3].imshow(y_pred_unet_sa[:, :, 0], cmap='gray')
  axarr[0,4].imshow(gt, cmap='gray')

  axarr[1,0].imshow(original)
  axarr[1,1].imshow(y_pred_kiunet_noatt[:, :, 0], cmap='gray')
  axarr[1,2].imshow(y_pred_kiunet_ag[:, :, 0], cmap='gray')
  axarr[1,3].imshow(y_pred_kiunet_sa[:, :, 0], cmap='gray')
  axarr[1,4].imshow(gt, cmap='gray')

  axarr[0,0].title.set_text('Original')
  axarr[0,1].title.set_text('No attention mechanism')
  axarr[0,2].title.set_text('Attention Gates')
  axarr[0,3].title.set_text('Self Attention')
  axarr[0,4].title.set_text('Ground truth')

  axarr[0,0].set_xticks([])
  axarr[0,0].set_yticks([])
  axarr[0,1].set_xticks([])
  axarr[0,1].set_yticks([])
  axarr[0,2].set_xticks([])
  axarr[0,2].set_yticks([])
  axarr[0,3].set_xticks([])
  axarr[0,3].set_yticks([])
  axarr[0,4].set_xticks([])
  axarr[0,4].set_yticks([])

  axarr[1,0].set_xticks([])
  axarr[1,0].set_yticks([])
  axarr[1,1].set_xticks([])
  axarr[1,1].set_yticks([])
  axarr[1,2].set_xticks([])
  axarr[1,2].set_yticks([])
  axarr[1,3].set_xticks([])
  axarr[1,3].set_yticks([])
  axarr[1,4].set_xticks([])
  axarr[1,4].set_yticks([])

  plt.subplots_adjust(left=0.1,
                      bottom=0.1, 
                      right=0.9, 
                      top=0.9, 
                      wspace=0.02, 
                      hspace=0.01)

  plt.gcf().text(0.068, 0.7, 'U-Net', fontsize=14)
  plt.gcf().text(0.065, 0.3, 'KiU-Net', fontsize=14)

def whiten_and_dilate_or_erode(im, dilation=True, erosion=False, d_it=1, e_it=1, kernel=(4, 4)):
# im = y_pred_unet_sa[0][:, :, 0]
  im = Image.fromarray(np.uint8(im*255))
  #image brightness enhancer
  enhancer = ImageEnhance.Brightness(im)

  factor = 1.5 #gives original image
  im_output = enhancer.enhance(factor)

  im_output = np.round(np.asarray(im_output)/255.0)

  if dilation:
    # kernel = np.ones((4,4), np.uint8)
    im_output = cv.dilate(im_output, kernel, iterations=d_it)
  
  if erosion:
    im_output = cv.erode(im_output, kernel, iterations=e_it)
  
  img = im_output.reshape(im_output.shape + (1,))
  return img

def rotate_image(img, angle):
  image_center = tuple(np.array(img.shape[1::-1]) / 2)
  rot_mat = cv.getRotationMatrix2D(image_center, angle, 1.0)
  result = cv.warpAffine(img, rot_mat, img.shape[1::-1], flags=cv.INTER_LINEAR, borderMode=cv.BORDER_CONSTANT, borderValue=(0,0,0))
  return result

def flip_image_x(img):
  flipped = cv.flip(img, 0)
  return flipped

def flip_image_y(img):
  flipped = cv.flip(img, 1)
  return flipped

def flip_image_xy(img):
  flipped = cv.flip(img, 1)
  return flipped

def augment(x, y):
  x_augmented, y_augmented = [], []
  for i in range(len(x)):
    x_augmented.append(rotate_image(x[i], angle=90))
    y_augmented.append(rotate_image(y[i], angle=90))
    x_augmented.append(rotate_image(x[i], angle=180))
    y_augmented.append(rotate_image(y[i], angle=180))
    x_augmented.append(rotate_image(x[i], angle=270))
    y_augmented.append(rotate_image(y[i], angle=270))
    x_augmented.append(flip_image_x(x[i]))
    y_augmented.append(flip_image_x(y[i]))
    x_augmented.append(flip_image_y(x[i]))
    y_augmented.append(flip_image_y(y[i]))
    x_augmented.append(flip_image_xy(x[i]))
    y_augmented.append(flip_image_xy(y[i]))
  return x_augmented, y_augmented

"""## Read data"""

dim1_wanted, dim2_wanted = 128, 128

# paths
path_project = '/content/drive/My Drive/Disertatie'

# path_data = get_specific_path(path_project, 'Data', 'colonoscopy')
# path_data = get_specific_path(path_project, 'Data', 'rite', 'original')
# path_data = get_specific_path(path_project, 'Data', 'rite')
dataset = 'rite'
path_data = get_specific_path(path_project, 'Data', dataset)

x_dir_name = 'img'
y_dir_name = 'label'
# img_ext = '*.jpg'  # colonoscopy
img_ext = '*.png'  # rite
# img_ext = '*.bmp'  # glas

path_models = get_specific_path(path_project, 'Models')
path_results = get_specific_path(path_project, 'Results')


# data reading and processing
x, y = read_data(path_data, x_dir_name, y_dir_name, img_ext)
x, y = preprocess_data(x, y, dim1_wanted, dim2_wanted, dataset=dataset)
# x, y = preprocess_data(x, y)

x_train, y_train, x_test, y_test, x_val, y_val = split(x, y)
if x_test.shape[0] % 2 == 1:
  x_test = x_test[:(x_test.shape[0] - 1)]
  y_test = y_test[:(y_test.shape[0] - 1)]
if x_val.shape[0] % 2 == 1:
  x_val = x_val[:(x_val.shape[0] - 1)]
  y_val = y_val[:(y_val.shape[0] - 1)]

"""## Training"""

# pretraining universals
model_name = 'unet'
nr_epochs = 30

patch_size = 2
num_patches = (x_train.shape[1] * x_train.shape[2]) // (patch_size * patch_size)
embedding_dim = 64  # Number of hidden units.
num_transformer_blocks = 2  # Number of repetitions of the transformer layer

metrics = [custom_mae_metric, 
           custom_mse_metric, 
           custom_meanIoU_metric, 
           custom_accuracy_metric,
           custom_precision_metric, 
           custom_recall_metric, 
           custom_dice_metric]

optimizer = "Adam"
dataset = 'rite'
# optimizer = Adam(learning_rate=1e-3, epsilon=1e-5)

# 1 training 
# No Attention, relu, mse
##########################
attention = False
self_attention = False
final_layer_activation = 'relu'  # relu, sigmoid
loss = "mse"  # "binary_crossentropy", "mae", "mse"
batch_size = 2
##########################

current_model_path = get_model_path(path_models,
                                    dataset,
                                    model_name, 
                                    attention=attention,
                                    nr_epochs=nr_epochs, 
                                    final_layer_activation=final_layer_activation, 
                                    loss=loss,
                                    batch_size=batch_size)

# current_model_path = get_specific_path(path_models, model_name, 'self_attention', 'nr_epochs=30', '2')
tensorboard_dir = get_specific_path(current_model_path, 'tensorboard_logs')

callbacks = [get_callback_model_checkpoint(current_model_path),
             get_callback_reduce_lr(),
             get_callback_tensorboard(tensorboard_dir)]


 # model configuring
model = get_model(model_name, 
                  x_train.shape[1:], 
                  final_layer_activation,
                  attention=attention,
                  self_attention=self_attention,
                  patch_size=patch_size,
                  num_patches=num_patches,
                  embedding_dim=embedding_dim,
                  num_transformer_blocks=num_transformer_blocks)
model.compile(optimizer=optimizer, loss=loss, metrics=metrics, run_eagerly=True)

# model fit
history = model.fit(x_train, y_train,
                    validation_data=(x_val, y_val), 
                    batch_size=batch_size, 
                    epochs=nr_epochs,
                    callbacks=callbacks)

save_train_artifacts(model, current_model_path, batch_size, history, x_test, y_test)

"""### Results

#### Plot (2x2 grid)
"""

model_name = 'unet'
attention = 'self_attention'
nr_epochs = 30
final_layer_activation = 'relu'  # relu, sigmoid
loss = 'mse'  # binary_crossentropy, mae, mse
batch_size = 2

current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
history, y_pred, results = load_train_artifacts(current_model_path)
get_results_test(results)
plot_history('accuracy', history)
print()
plot_results(x_test, y_test, y_pred, img_index=1)

"""#### colonoscopy"""

dataset = 'colonoscopy'
nr_epochs = 30
batch_size = 2

# colonoscopy results
model_name = 'unet'
final_layer_activation = 'relu'
loss = 'mse'

original = x_test

attention = False
self_attention=False

current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
model = load_best_model(current_model_path, custom_objects)
_, y_pred_unet_noatt, _ = load_train_artifacts(current_model_path, x_test=x_test, y_test=y_test, batch_size=2, model=model)





attention = True
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_unet_ag, _ = load_train_artifacts(current_model_path)

attention = 'self_attention'
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_unet_sa, _ = load_train_artifacts(current_model_path)



model_name = 'kiunet'
final_layer_activation = 'relu'
loss = 'mse'

attention = False
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_kiunet_noatt, _ = load_train_artifacts(current_model_path)

attention = True
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
model = load_best_model(current_model_path, custom_objects)
_, y_pred_kiunet_ag, _ = load_train_artifacts(current_model_path, x_test=x_test, y_test=y_test, batch_size=2, model=model)

attention = 'self_attention'
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_kiunet_sa, _ = load_train_artifacts(current_model_path)

gt = y_test

img_index=5

# original
u0 = y_pred_unet_noatt[img_index]
u1 = y_pred_unet_ag[img_index]
u2 = y_pred_unet_sa[img_index]

k0 = y_pred_kiunet_noatt[img_index]
k1 = y_pred_kiunet_ag[img_index]
k2 = y_pred_kiunet_sa[img_index]

plot_results_all(original[img_index], u0, u1, u2, k0, k1, k2, gt[img_index])

# rounded
u0 = np.round(y_pred_unet_noatt[img_index])
u1 = np.round(y_pred_unet_ag[img_index])
u2 = np.round(y_pred_unet_sa[img_index])

k0 = np.round(y_pred_kiunet_noatt[img_index])
k1 = np.round(y_pred_kiunet_ag[img_index])
k2 = np.round(y_pred_kiunet_sa[img_index])

plot_results_all(original[img_index], u0, u1, u2, k0, k1, k2, gt[img_index])

"""#### glas"""

dataset = 'glas'
nr_epochs = 30
batch_size = 2

# glas results
model_name = 'unet'
final_layer_activation = 'relu'
loss = 'mse'

original = x_test

attention = False
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_unet_noatt, _ = load_train_artifacts(current_model_path)

attention = True
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_unet_ag, _ = load_train_artifacts(current_model_path)

attention = 'self_attention'
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_unet_sa, _ = load_train_artifacts(current_model_path)



model_name = 'kiunet'
final_layer_activation = 'relu'
loss = 'mse'
attention = False
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_kiunet_noatt, _ = load_train_artifacts(current_model_path)

final_layer_activation = 'relu'
loss = 'mae'
attention = True
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_kiunet_ag, _ = load_train_artifacts(current_model_path)

final_layer_activation = 'sigmoid'
loss = 'mae'
attention = 'self_attention'
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_kiunet_sa, _ = load_train_artifacts(current_model_path)

gt = y_test

img_index=1

# rounded
u0 = np.round(y_pred_unet_noatt[img_index])
u1 = np.round(y_pred_unet_ag[img_index])
u2 = np.round(y_pred_unet_sa[img_index])

k0 = np.round(y_pred_kiunet_noatt[img_index])
k1 = np.round(y_pred_kiunet_ag[img_index])
k2 = np.round(y_pred_kiunet_sa[img_index])

plot_results_all(original[img_index], u0, u1, u2, k0, k1, k2, gt[img_index])

# glas results
# edited
u0 = whiten_and_dilate_or_erode(np.round(y_pred_unet_noatt[img_index][:, :, 0]), dilation=False, erosion=True, e_it=5)
u1 = whiten_and_dilate_or_erode(np.round(y_pred_unet_ag[img_index][:, :, 0]), dilation=True, erosion=False, d_it=4)
u2 = whiten_and_dilate_or_erode(np.round(y_pred_unet_sa[img_index][:, :, 0]), dilation=False, erosion=True, e_it=3)

k0 = whiten_and_dilate_or_erode(np.round(y_pred_kiunet_noatt[img_index][:, :, 0]), dilation=False, erosion=True, e_it=3, kernel=(7,7))
k1 = whiten_and_dilate_or_erode(np.round(y_pred_kiunet_ag[img_index][:, :, 0]), dilation=False, erosion=True, e_it=3, kernel=(5,5))
k2 = whiten_and_dilate_or_erode(np.round(y_pred_kiunet_sa[img_index][:, :, 0]), dilation=False, erosion=True, e_it=3, kernel=(5,5))

plot_results_all(original[img_index], u0, u1, u2, k0, k1, k2, gt[img_index])

"""#### rite"""

dataset = 'rite'
nr_epochs = 30
batch_size = 2

model_name = 'unet'
final_layer_activation = 'relu'
loss = 'mse'

original = x_test

attention = False
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_unet_noatt, _ = load_train_artifacts(current_model_path)

attention = True
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_unet_ag, _ = load_train_artifacts(current_model_path)

attention = 'self_attention'
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_unet_sa, _ = load_train_artifacts(current_model_path)



model_name = 'kiunet'
final_layer_activation = 'relu'
loss = 'mse'
attention = False
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_kiunet_noatt, _ = load_train_artifacts(current_model_path)

final_layer_activation = 'sigmoid'
loss = 'mae'
attention = True
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_kiunet_ag, _ = load_train_artifacts(current_model_path)

final_layer_activation = 'sigmoid'
loss = 'mse'
attention = 'self_attention'
current_model_path = get_model_path(path_models, dataset, model_name, attention=attention, nr_epochs=nr_epochs, final_layer_activation=final_layer_activation, loss=loss, batch_size=batch_size)
_, y_pred_kiunet_sa, _ = load_train_artifacts(current_model_path)

gt = y_test

img_index=8

u0 = y_pred_unet_noatt[img_index]
u1 = y_pred_unet_ag[img_index]
u2 = y_pred_unet_sa[img_index]

k0 = y_pred_kiunet_noatt[img_index]
k1 = y_pred_kiunet_ag[img_index]
k2 = y_pred_kiunet_sa[img_index]

plot_results_all(original[img_index], u0, u1, u2, k0, k1, k2, gt[img_index])